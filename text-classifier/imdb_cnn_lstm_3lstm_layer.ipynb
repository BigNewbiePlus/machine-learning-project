{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "x_train shape: (25000, 500)\n",
      "x_test shape: (25000, 500)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           16000     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 88,309.0\n",
      "Trainable params: 88,309.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 990s - loss: 0.5337 - acc: 0.7199 - val_loss: 0.4082 - val_acc: 0.8190\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 993s - loss: 0.4389 - acc: 0.8049 - val_loss: 0.3837 - val_acc: 0.8342\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 994s - loss: 0.4164 - acc: 0.8132 - val_loss: 0.3727 - val_acc: 0.8376\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 997s - loss: 0.3866 - acc: 0.8307 - val_loss: 0.3593 - val_acc: 0.8440\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 997s - loss: 0.3809 - acc: 0.8345 - val_loss: 0.3557 - val_acc: 0.8464\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 998s - loss: 0.3646 - acc: 0.8425 - val_loss: 0.3493 - val_acc: 0.8482\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 997s - loss: 0.3589 - acc: 0.8460 - val_loss: 0.3437 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 1000s - loss: 0.3578 - acc: 0.8475 - val_loss: 0.3416 - val_acc: 0.8536\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 999s - loss: 0.3454 - acc: 0.8542 - val_loss: 0.3428 - val_acc: 0.8515\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 996s - loss: 0.3457 - acc: 0.8518 - val_loss: 0.3425 - val_acc: 0.8518\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 1000s - loss: 0.3396 - acc: 0.8539 - val_loss: 0.3404 - val_acc: 0.8538\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 1000s - loss: 0.3308 - acc: 0.8594 - val_loss: 0.3341 - val_acc: 0.8547\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 999s - loss: 0.3321 - acc: 0.8594 - val_loss: 0.3481 - val_acc: 0.8483\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 999s - loss: 0.3246 - acc: 0.8628 - val_loss: 0.3349 - val_acc: 0.8530\n",
      "Epoch 15/20\n",
      "11456/25000 [============>.................] - ETA: 386s - loss: 0.3167 - acc: 0.8687"
     ]
    }
   ],
   "source": [
    "# LSTM and CNN for sequence classification in the IMDB dataset\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.append('datasets')\n",
    "\n",
    "import numpy\n",
    "import codeforces\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 500\n",
    "max_len = 500\n",
    "embed_dim = 32\n",
    "lstm_size = 100\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "dropout = 0.2\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "# create the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embed_dim, input_length=max_len))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Conv1D(padding=\"same\", kernel_size=3,activation='relu',filters=64))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(lstm_size, dropout=dropout, recurrent_dropout=dropout, return_sequences=True))\n",
    "model.add(LSTM(lstm_size, dropout=dropout, recurrent_dropout=dropout, return_sequences=True))\n",
    "model.add(LSTM(lstm_size, dropout=dropout, recurrent_dropout=dropout))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
