{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "18537 train sequences\n",
      "4635 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (18537, 500)\n",
      "x_test shape: (4635, 500)\n",
      "Train...\n",
      "Train on 18537 samples, validate on 4635 samples\n",
      "Epoch 1/10\n",
      "18537/18537 [==============================] - 7287s - loss: 0.6734 - acc: 0.5872 - val_loss: 0.6812 - val_acc: 0.5683\n",
      "Epoch 2/10\n",
      "18537/18537 [==============================] - 6172s - loss: 0.6529 - acc: 0.6172 - val_loss: 0.6431 - val_acc: 0.6263\n",
      "Epoch 3/10\n",
      "18537/18537 [==============================] - 5093s - loss: 0.6144 - acc: 0.6566 - val_loss: 0.6060 - val_acc: 0.6606\n",
      "Epoch 4/10\n",
      "18537/18537 [==============================] - 4787s - loss: 0.6218 - acc: 0.6469 - val_loss: 0.6194 - val_acc: 0.6388\n",
      "Epoch 5/10\n",
      "18537/18537 [==============================] - 5143s - loss: 0.5847 - acc: 0.6836 - val_loss: 0.5918 - val_acc: 0.6919\n",
      "Epoch 6/10\n",
      "18537/18537 [==============================] - 3582s - loss: 0.5636 - acc: 0.7055 - val_loss: 0.5802 - val_acc: 0.6999\n",
      "Epoch 7/10\n",
      "18537/18537 [==============================] - 3837s - loss: 0.5486 - acc: 0.7154 - val_loss: 0.5746 - val_acc: 0.7109\n",
      "Epoch 8/10\n",
      "18537/18537 [==============================] - 4011s - loss: 0.5368 - acc: 0.7240 - val_loss: 0.5796 - val_acc: 0.7102\n",
      "Epoch 9/10\n",
      "18537/18537 [==============================] - 2371s - loss: 0.5792 - acc: 0.6994 - val_loss: 0.5605 - val_acc: 0.7102\n",
      "Epoch 10/10\n",
      "10688/18537 [================>.............] - ETA: 918s - loss: 0.5450 - acc: 0.7215"
     ]
    }
   ],
   "source": [
    "'''Train a Bidirectional LSTM on the IMDB sentiment classification task.\n",
    "Output after 4 epochs on CPU: ~0.8146\n",
    "Time per epoch on CPU (Core i7): ~150s.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('datasets')\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.datasets import imdb\n",
    "\n",
    "import codeforces\n",
    "top_words = 500\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "max_len = 1000\n",
    "batch_size = 64\n",
    "embed_dim = 128\n",
    "lstm_size = 200\n",
    "dropout = 0.25\n",
    "epochs = 10\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = codeforces.load_data(path='../data/codeforces_full.pkl',\n",
    "                                                            num_words=top_words)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embed_dim, input_length=max_len))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Bidirectional(LSTM(lstm_size, dropout=dropout, recurrent_dropout=dropout, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(lstm_size, dropout=dropout, recurrent_dropout=dropout, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(lstm_size, dropout=dropout, recurrent_dropout=dropout)))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=[x_test, y_test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
