{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "11586 train sequences\n",
      "11586 test sequences\n",
      "x_train shape: (11586, 500)\n",
      "x_test shape: (11586, 500)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           16000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 250, 100)          66000     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 250, 64)           19264     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 125, 100)          66000     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 125, 64)           19264     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 258,837.0\n",
      "Trainable params: 258,837.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 11586 samples, validate on 11586 samples\n",
      "Epoch 1/20\n",
      "11586/11586 [==============================] - 1071s - loss: 0.6729 - acc: 0.5635 - val_loss: 0.6547 - val_acc: 0.6422\n",
      "Epoch 2/20\n",
      "11586/11586 [==============================] - 1065s - loss: 0.6248 - acc: 0.6497 - val_loss: 0.5995 - val_acc: 0.6789\n",
      "Epoch 3/20\n",
      "11586/11586 [==============================] - 1003s - loss: 0.6028 - acc: 0.6751 - val_loss: 0.5936 - val_acc: 0.6862\n",
      "Epoch 4/20\n",
      "11586/11586 [==============================] - 995s - loss: 0.5881 - acc: 0.6910 - val_loss: 0.5835 - val_acc: 0.6912\n",
      "Epoch 5/20\n",
      "11586/11586 [==============================] - 971s - loss: 0.5848 - acc: 0.6963 - val_loss: 0.5743 - val_acc: 0.6991\n",
      "Epoch 6/20\n",
      "11586/11586 [==============================] - 943s - loss: 0.5704 - acc: 0.7033 - val_loss: 0.5702 - val_acc: 0.7078\n",
      "Epoch 7/20\n",
      "11586/11586 [==============================] - 1005s - loss: 0.5708 - acc: 0.7013 - val_loss: 0.5719 - val_acc: 0.7052\n",
      "Epoch 8/20\n",
      "11586/11586 [==============================] - 987s - loss: 0.5643 - acc: 0.7084 - val_loss: 0.5693 - val_acc: 0.7062\n",
      "Epoch 9/20\n",
      "11586/11586 [==============================] - 986s - loss: 0.5562 - acc: 0.7161 - val_loss: 0.5888 - val_acc: 0.6954\n",
      "Epoch 10/20\n",
      "11586/11586 [==============================] - 993s - loss: 0.5541 - acc: 0.7147 - val_loss: 0.5680 - val_acc: 0.7033\n",
      "Epoch 11/20\n",
      "11586/11586 [==============================] - 979s - loss: 0.5499 - acc: 0.7172 - val_loss: 0.5816 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "11586/11586 [==============================] - 955s - loss: 0.5500 - acc: 0.7198 - val_loss: 0.5622 - val_acc: 0.7074\n",
      "Epoch 13/20\n",
      "11586/11586 [==============================] - 1007s - loss: 0.5417 - acc: 0.7274 - val_loss: 0.5626 - val_acc: 0.7111\n",
      "Epoch 14/20\n",
      "11586/11586 [==============================] - 1014s - loss: 0.5391 - acc: 0.7288 - val_loss: 0.5664 - val_acc: 0.7020\n",
      "Epoch 15/20\n",
      "11586/11586 [==============================] - 1010s - loss: 0.5379 - acc: 0.7289 - val_loss: 0.5645 - val_acc: 0.7126\n",
      "Epoch 16/20\n",
      "11586/11586 [==============================] - 1008s - loss: 0.5365 - acc: 0.7287 - val_loss: 0.5578 - val_acc: 0.7190\n",
      "Epoch 17/20\n",
      "11586/11586 [==============================] - 958s - loss: 0.5288 - acc: 0.7382 - val_loss: 0.5640 - val_acc: 0.7082\n",
      "Epoch 18/20\n",
      "11586/11586 [==============================] - 962s - loss: 0.5276 - acc: 0.7358 - val_loss: 0.5637 - val_acc: 0.7084\n",
      "Epoch 19/20\n",
      "11586/11586 [==============================] - 995s - loss: 0.5270 - acc: 0.7333 - val_loss: 0.5600 - val_acc: 0.7115\n",
      "Epoch 20/20\n",
      "11586/11586 [==============================] - 1003s - loss: 0.5244 - acc: 0.7416 - val_loss: 0.5640 - val_acc: 0.7138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e546e2e50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM and CNN for sequence classification in the IMDB dataset\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.append('datasets')\n",
    "\n",
    "import numpy\n",
    "import codeforces\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 500\n",
    "max_len = 500\n",
    "embed_dim = 32\n",
    "lstm_size = 100\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "dropout = 0.2\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = codeforces.load_data(num_words=top_words)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "# create the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embed_dim, input_length=max_len))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Conv1D(padding=\"same\", kernel_size=3,activation='relu',filters=64))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(lstm_size, dropout=dropout, recurrent_dropout=dropout, return_sequences=True))\n",
    "model.add(Conv1D(padding=\"same\", kernel_size=3,activation='relu',filters=64))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(lstm_size, dropout=dropout, recurrent_dropout=dropout, return_sequences=True))\n",
    "model.add(Conv1D(padding=\"same\", kernel_size=3,activation='relu',filters=64))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(lstm_size, dropout=dropout, recurrent_dropout=dropout))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#评估模型好坏\n",
    "#precision = TP / (TP + FP)\n",
    "#recall = TP / (TP + FN)\n",
    "#accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "#F1 Score = 2*P*R/(P+R)，其中P和R分别为 precision 和 recall\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "y_preds = np.round(model.predict(x_test))\n",
    "result = precision_recall_fscore_support(y_test, y_preds, average='binary')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ROC曲线和AUC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr={}\n",
    "tpr={}\n",
    "roc_auc={}\n",
    "\n",
    "y_score1 = model.predict(x_test)\n",
    "y_score2 = model.predict(x_train)\n",
    "\n",
    "fpr['test'], tpr['test'], _ = roc_curve(y_test, y_score1)\n",
    "roc_auc['test'] = auc(fpr['test'], tpr['test'])\n",
    "fpr['train'], tpr['train'], _ = roc_curve(y_train, y_score2)\n",
    "roc_auc['train'] = auc(fpr['train'], tpr['train'])\n",
    "    \n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr['test'], tpr['test'], color='aqua',\n",
    "         lw=lw, label='Test ROC curve (area = %0.2f)' % roc_auc['test'])\n",
    "plt.plot(fpr['train'], tpr['train'], color='darkorange',\n",
    "         lw=lw, label='Train ROC curve (area = %0.2f)' % roc_auc['train'])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "tick_nb = 20\n",
    "ticks = [x/tick_nb for x in range(1, tick_nb)]\n",
    "labels = ['%.1f'%tick if tick*10%1==0 else '' for tick in ticks]\n",
    "plt.xticks(ticks, labels)\n",
    "plt.yticks(ticks, labels)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC for codeforces classification')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
