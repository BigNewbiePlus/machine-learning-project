{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 500, 32)       160000      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 500, 32)       0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 100)           53200       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100)           0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             101         dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 213301\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lupeng/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 1573s - loss: 0.6223 - acc: 0.6502  \n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 1556s - loss: 0.4536 - acc: 0.7918  \n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 1541s - loss: 0.3542 - acc: 0.8523  \n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 1548s - loss: 0.3082 - acc: 0.8745  \n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 1551s - loss: 0.3144 - acc: 0.8707  \n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 1561s - loss: 0.2933 - acc: 0.8792  \n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 1535s - loss: 0.2555 - acc: 0.8996  \n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 1463s - loss: 0.2429 - acc: 0.9030  \n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 1465s - loss: 0.2229 - acc: 0.9119  \n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 1470s - loss: 0.2153 - acc: 0.9148  \n",
      "Accuracy: 86.82%\n"
     ]
    }
   ],
   "source": [
    "# LSTM with Dropout for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(path='imdb_full.pkl',nb_words=top_words)\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length, dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
